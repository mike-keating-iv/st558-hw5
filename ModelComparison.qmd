---
title: "Model Comparison"
author: "Mike Keating"
format: pdf
editor: visual
---

# Model Comparison

## Task 1: Conceptual Questions

-   What is the purpose of using cross-validation when fitting a random forest model?

    Cross-validation is an important method to reduce risk of over fitting a model and to prevent data leakage. Since CV is performed on multiple data splits, it helps form a better understanding of a random forest models performance on unseen (i.e. real world) data.

-   Describe the bagged tree algorithm.

    Bagging stands for "bootstrap aggregation" in which multiple tree models are trained on bootstrapped data sets and the results aggregated to form the model's prediction. Bootstrapping is a sub sampling method that utilizes replacement, so each tree is trained on sub samples with varying compositions based on the original training set.

-   What is meant by a general linear model?

    A general linear model is a generic framework for predicting the response of a dependent variable on one or more independent variables (regressors).

-    When fitting a multiple linear regression model, what does adding an interaction term
    do? That is, what does it allow the model to do differently as compared to when it is
    not included in the model?

    Adding an interaction term accounts for the situation where the value of one regressor can depend on the value of another regressor. This is represented in the formula as a product of these terms.

-   Why do we split our data into a training and test set?

    In order to test the effectiveness of our model in real world situations, it needs to be tested on data that it was not trained on. Otherwise, the model may be over fit to the training data and the model would have poor generalization.

## Task 2: Data Prep

#### Packages and Data

```{r message=FALSE}
# Load Dependencies
library(tidyverse)
library(tidymodels)
library(caret)
library(yardstick)
```

```{r}
heart <- read_csv("data/heart.csv", show_col_types = FALSE)
summary(heart)
```

#### What type of variable (in R) is Heart Disease? Categorical or Quantitative?

Heart disease is a quantitative variable (double)

#### Does this make sense? Why or why not?

This does not make sense - as this variable should be treated as a factor, since it is a binary classification.

```{r}
# Change heart disease to the correct type
# Perform some dataset cleanup

heart <- heart |> 
  mutate(HasHeartDisease = as_factor(HeartDisease)) |> 
  select(!c(ST_Slope, HeartDisease))

head(heart)
```

## Task 3: EDA

```{r}
library(ggplot2)
 # NOTE: Check to see if I am understanding the prompt correctly...
g <- ggplot(heart, aes(x = MaxHR, y = Age, color=HasHeartDisease)) + 
  geom_point(aes(alpha = 0.8)) +
  geom_smooth(method = "lm", se=FALSE) + 
  labs() + 
  theme_gray()
g
```

## Task 4: Testing and Training

#### Split into test and train sets

```{r}
# Set random seed
set.seed(101)

# Split into test and train sets
heart_split <- heart |> initial_split(prop=0.8)
train <- training(heart_split)
test <- testing(heart_split)

```

## Task 5: OLS and LASSO

#### Fit Interaction Model

```{r}
# Fit model
ols_mlr <- lm(Age ~ HasHeartDisease + MaxHR + HasHeartDisease:MaxHR, data = train)
#summary(ols_mlr)

# Recipe
# TODO: Fix this
ols_mlr_rec <- recipe(Age ~ HasHeartDisease + MaxHR, data = train) |> step_normalize(all_numeric(), -all_outcomes()) |> step_interact(terms = ~ HasHeartDisease)
```

```{:MaxHR)}

# Model
ols_mlr <- linear_reg() |> set_engine("lm")

# Workflow
ols_mlr_wfl <- workflow() |> add_recipe(ols_mlr_rec) |> add_model(ols_mlr)
ols_mlr_fit <- ols_mlr_wfl |> fit(train)

ols_mlr_fit |> tidy()
```

#### Find RMSE

```{r}
# Collect metrics/performance on the test set
ols_mlr_wfl |> last_fit(heart_split) |> collect_metrics()

```

#### LASSO

```{r}
LASSO_recipe <- recipe(Age ~ HasHeartDisease + MaxHR, data = train) |> 
  step_dummy(all_nominal_predictors()) |> 
  step_interact(terms = ~ HasHeartDisease:MaxHR) |>
  step_normalize(all_numeric_predictors()) 
  
LASSO_recipe
```

```{r}
# recall mixture = 1 sets to LASSO
LASSO_spec <- linear_reg(penalty = tune(), mixture = 1) |> 
  set_engine("glmnet")

LASSO_wkf <- workflow() |> add_recipe(LASSO_recipe) |> add_model(LASSO_spec)

heart_cv_folds <- vfold_cv(train, 5)

# Create grid object
LASSO_grid <- LASSO_wkf |>
  tune_grid(resamples = heart_cv_folds,
            grid = grid_regular(penalty(),
                               levels = 20))
```

## Task 6: Linear Regression
